{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crocoddyl: Contact RObot COntrol by Differential DYnamic programming Library\n",
    "\n",
    "\n",
    "## I. Welcome to crocoddyl\n",
    "Crocoddyl is an **optimal control library for robot control under contact sequence**. Its solver is based on an efficient Differential Dynamic Programming (DDP) algorithm. Crocoddyl computes optimal trajectories along to optimal feedback gains. It uses Pinocchio for fast computation of robot dynamics and its analytical derivatives. \n",
    "\n",
    "Crocoddyl is focused on multi-contact optimal control problem (MCOP) which as the form:\n",
    "\n",
    "$$\\mathbf{X}^*,\\mathbf{U}^*=\n",
    "\\begin{Bmatrix} \\mathbf{x}^*_0,\\cdots,\\mathbf{x}^*_N \\\\\n",
    "\t\t\t\t  \\mathbf{u}^*_0,\\cdots,\\mathbf{u}^*_N\n",
    "\\end{Bmatrix} =\n",
    "\\arg\\min_{\\mathbf{X},\\mathbf{U}} \\sum_{k=1}^N \\int_{t_k}^{t_k+\\Delta t} l(\\mathbf{x},\\mathbf{u})dt$$\n",
    "subject to\n",
    "$$ \\mathbf{\\dot{x}} = \\mathbf{f}(\\mathbf{x},\\mathbf{u}),$$\n",
    "$$ \\mathbf{x}\\in\\mathcal{X}, \\mathbf{u}\\in\\mathcal{U}, \\boldsymbol{\\lambda}\\in\\mathcal{K}.$$\n",
    "where\n",
    " - the state $\\mathbf{x}=(\\mathbf{q},\\mathbf{v})$ lies in a manifold, e.g. Lie manifold $\\mathbf{q}\\in SE(3)\\times \\mathbb{R}^{n_j}$,\n",
    " - the system has underactuacted dynamics, i.e. $\\mathbf{u}=(\\mathbf{0},\\boldsymbol{\\tau})$,\n",
    " - $\\mathcal{X}$, $\\mathcal{U}$ are the state and control admissible sets, and\n",
    " - $\\mathcal{K}$ represents the contact constraints.\n",
    " \n",
    " Note that $\\boldsymbol{\\lambda}=\\mathbf{g}(\\mathbf{x},\\mathbf{u})$ denotes the contact force, and is dependent on the state and control.\n",
    " \n",
    "Let's start by understanding the concept behind crocoddyl design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Action models\n",
    "\n",
    "In crocoddyl, an action model combines dynamics and cost models. Each node, in our optimal control problem, is described through an action model. Every time that we want describe a problem, we need to provide ways of computing the dynamics, cost functions and their derivatives. All these is described inside the action model.\n",
    "\n",
    "To understand the mathematical aspects behind an action model, let's first get a locally linearize version of our optimal control problem as:\n",
    "\n",
    "$$\\mathbf{X}^*(\\mathbf{x}_0),\\mathbf{U}^*(\\mathbf{x}_0)\n",
    "=\n",
    "\\arg\\max_{\\mathbf{X},\\mathbf{U}} = cost_T(\\delta\\mathbf{x}_N) + \\sum_{k=1}^N cost_t(\\delta\\mathbf{x}_k, \\delta\\mathbf{u}_k)$$\n",
    "subject to\n",
    "$$dynamics(\\delta\\mathbf{x}_{k+1},\\delta\\mathbf{x}_k,\\delta\\mathbf{u}_k)=\\mathbf{0},$$\n",
    "\n",
    "where\n",
    "$$cost_T(\\delta\\mathbf{x}) = \\frac{1}{2}\n",
    "\\begin{bmatrix} \n",
    "  1 \\\\ \\delta\\mathbf{x}\n",
    "\\end{bmatrix}^\\top\n",
    "\\begin{bmatrix}\n",
    "0 & \\mathbf{l_x}^\\top \\\\\n",
    "\\mathbf{l_x} & \\mathbf{l_{xx}}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \\delta\\mathbf{x}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$cost_t(\\delta\\mathbf{x},\\delta\\mathbf{u}) = \\frac{1}{2}\n",
    "\\begin{bmatrix} \n",
    "  1 \\\\ \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u}\n",
    "\\end{bmatrix}^\\top\n",
    "\\begin{bmatrix}\n",
    "0 & \\mathbf{l_x}^\\top & \\mathbf{l_u}^\\top\\\\\n",
    "\\mathbf{l_x} & \\mathbf{l_{xx}} & \\mathbf{l_{ux}}^\\top\\\\\n",
    "\\mathbf{l_u} & \\mathbf{l_{ux}} & \\mathbf{l_{uu}}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "dynamics(\\delta\\mathbf{x}_{k+1},\\delta\\mathbf{x}_k,\\delta\\mathbf{u}_k) = \\delta\\mathbf{x}_{k+1} - (\\mathbf{f_x}\\delta\\mathbf{x}_k + \\mathbf{f_u}\\delta\\mathbf{u}_k)\n",
    "$$\n",
    "\n",
    "where an action model defines a time interval of this problem:\n",
    " - $actions = dynamics + cost$\n",
    "\n",
    "### Important notes:\n",
    " - An action model describes the dynamics and cost functions for a node in our optimal control problem.\n",
    " - Action models lie in the discrete time space.\n",
    " - For debugging and prototyping, we have also implemented NumDiff abstractions. These computations depend only in the defining of the dynamics equation and cost functions. However to asses efficiency, crocoddyl uses **analytical derivatives** computed from Pinocchio.\n",
    "\n",
    "\n",
    "## II.a Differential and Integrated Action Models\n",
    "Optimal control solvers require the time-discrete model of cost and dynamics. However, it's often convenient to implement them in continuous time (e.g. to combine with abstract integration rules). In crocoddyl, this continuous-time action models are called \"Differential Action Model (DAM)\". And together with predefined \"Integrated Action Models (IAM)\", it possible to retrieve the time-discrete action model.\n",
    "\n",
    "At the moment, we have:\n",
    " - a simpletic Euler and\n",
    " - a Runge-Kutte 4 integration rules.\n",
    "\n",
    "An optimal control problem can be written from a set of DAMs as:\n",
    "$$\\mathbf{X}^*(\\mathbf{x}_0),\\mathbf{U}^*(\\mathbf{x}_0)\n",
    "=\n",
    "\\arg\\max_{\\mathbf{X},\\mathbf{U}} = cost_T(\\delta\\mathbf{x}_N) + \\sum_{k=1}^N \\int_{t_k}^{t_k+\\Delta t} cost_t(\\delta\\mathbf{x}_k, \\delta\\mathbf{u}_k) dt$$\n",
    "subject to\n",
    "$$dynamics(\\delta\\mathbf{x}_{k+1},\\delta\\mathbf{x}_k,\\delta\\mathbf{u}_k)=\\mathbf{0},$$\n",
    "\n",
    "where\n",
    "$$cost_T(\\delta\\mathbf{x}) = \\frac{1}{2}\n",
    "\\begin{bmatrix} \n",
    "  1 \\\\ \\delta\\mathbf{x}\n",
    "\\end{bmatrix}^\\top\n",
    "\\begin{bmatrix}\n",
    "0 & \\mathbf{l_x}^\\top \\\\\n",
    "\\mathbf{l_x} & \\mathbf{l_{xx}}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \\delta\\mathbf{x}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$cost_t(\\delta\\mathbf{x},\\delta\\mathbf{u}) = \\frac{1}{2}\n",
    "\\begin{bmatrix} \n",
    "  1 \\\\ \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u}\n",
    "\\end{bmatrix}^\\top\n",
    "\\begin{bmatrix}\n",
    "0 & \\mathbf{l_x}^\\top & \\mathbf{l_u}^\\top\\\\\n",
    "\\mathbf{l_x} & \\mathbf{l_{xx}} & \\mathbf{l_{ux}}^\\top\\\\\n",
    "\\mathbf{l_u} & \\mathbf{l_{ux}} & \\mathbf{l_{uu}}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \\delta\\mathbf{x} \\\\ \\delta\\mathbf{u}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "dynamics(\\delta\\mathbf{\\dot{x}},\\delta\\mathbf{x},\\delta\\mathbf{u}) = \\delta\\mathbf{\\dot{x}} - (\\mathbf{f_x}\\delta\\mathbf{x} + \\mathbf{f_u}\\delta\\mathbf{u})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a differential action model for robot forward dynamics\n",
    "#### Loading the robot\n",
    "\n",
    "Crocoddyl offers several robot models for benchmarking our optimal control solvers (e.g. manipulators, humanoids, quadrupeds, etc). The collection of Talos models can be downloaded in Ubuntu with the APT package *robotpkg-talos-data*.\n",
    "\n",
    "Let's load a single Talos arm (left one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crocoddyl import *\n",
    "import numpy as np\n",
    "\n",
    "talos_arm = loadTalosArm()\n",
    "\n",
    "# Defining a initial state\n",
    "q0 = [0.173046, 1., -0.52366, 0., 0., 0.1, -0.005]\n",
    "x0 = np.hstack([q0, np.zeros(talos_arm.model.nv)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calc and calcDiff\n",
    "Optimal control solvers often need to compute a quadratic approximation of the action model (as previously described); this provides a search direction (computeDirection). Then it's needed to try the step along this direction (tryStep).\n",
    "\n",
    "Typically calc and calcDiff do the precomputations that are required before computeDirection and tryStep respectively (inside the solver). These functions update the information of:\n",
    " - **calc**: update the next state and its cost value\n",
    " $$\\delta\\mathbf{\\dot{x}}_{k+1} = \\mathbf{f}(\\delta\\mathbf{x}_k,\\mathbf{u}_k)$$\n",
    " - **calcDiff**: update the derivatives of the dynamics and cost (quadratic approximation)\n",
    " $$\\mathbf{f_x}, \\mathbf{f_u} \\hspace{1em} (dynamics)$$\n",
    " $$\\mathbf{l_x}, \\mathbf{l_u}, \\mathbf{l_{xx}}, \\mathbf{l_{ux}}, \\mathbf{l_{uu}} \\hspace{1em} (cost)$$\n",
    " \n",
    " **Crocoddyl put all information inside data**, so avoiding dynamic reallocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pinocchio\n",
    "\n",
    "\n",
    "class DifferentialActionModelABA:\n",
    "    def __init__(self,pinocchioModel):\n",
    "        # The forward dynamics and its derivatives are computed with Pinocchio\n",
    "        self.pinocchio = pinocchioModel\n",
    "        self.nq,self.nv = self.pinocchio.nq, self.pinocchio.nv\n",
    "        \n",
    "        # Describes integrate, difference, Jacobian integrate and Jacobian difference\n",
    "        # for any Pinocchio model\n",
    "        self.State = StatePinocchio(self.pinocchio)\n",
    "        \n",
    "        # Keeps a stack of cost functions\n",
    "        self.costs = CostModelSum(self.pinocchio)\n",
    "        \n",
    "        # Dimension of the state, and its tangent space, and control\n",
    "        self.nx = self.State.nx\n",
    "        self.ndx = self.State.ndx\n",
    "        self.nout = self.nv\n",
    "        self.nu = self.nv\n",
    "        self.unone = np.zeros(self.nu)\n",
    "    @property\n",
    "    def ncost(self): return self.costs.ncost\n",
    "    def createData(self): return DifferentialActionDataABA(self) # create the data needed for this model\n",
    "    def calc(model,data,x,u=None):\n",
    "        if u is None: u=model.unone\n",
    "        nx,nu,nq,nv,nout = model.nx,model.nu,model.nq,model.nv,model.nout\n",
    "        q = a2m(x[:nq]) # from np array to matrix\n",
    "        v = a2m(x[-nv:]) # from np array to matrix\n",
    "        tauq = a2m(u) # from np array to matrix\n",
    "        \n",
    "        # Computes the next state through ABA\n",
    "        data.xout[:] = pinocchio.aba(model.pinocchio,data.pinocchio,q,v,tauq).flat\n",
    "        \n",
    "        # Updates the kinematics needed for cost computation\n",
    "        pinocchio.forwardKinematics(model.pinocchio,data.pinocchio,q,v)\n",
    "        pinocchio.updateFramePlacements(model.pinocchio,data.pinocchio)\n",
    "        \n",
    "        # Computes the cost from a set of single cost functions\n",
    "        data.cost = model.costs.calc(data.costs,x,u)\n",
    "        return data.xout,data.cost\n",
    "\n",
    "    def calcDiff(model,data,x,u=None,recalc=True):\n",
    "        if u is None: u=model.unone\n",
    "        if recalc: xout,cost = model.calc(data,x,u)\n",
    "        nx,ndx,nu,nq,nv,nout = model.nx,model.State.ndx,model.nu,model.nq,model.nv,model.nout\n",
    "        q = a2m(x[:nq]) # from np array to matrix\n",
    "        v = a2m(x[-nv:]) # from np array to matrix\n",
    "        tauq = a2m(u) # from np array to matrix\n",
    "        \n",
    "        # Computes the ABA derivatives (dynamics), and keeps them inside data\n",
    "        pinocchio.computeABADerivatives(model.pinocchio,data.pinocchio,q,v,tauq)\n",
    "        data.Fx[:,:nv] = data.pinocchio.ddq_dq\n",
    "        data.Fx[:,nv:] = data.pinocchio.ddq_dv\n",
    "        data.Fu[:,:]   = pinocchio.computeMinverse(model.pinocchio,data.pinocchio,q)\n",
    "\n",
    "        # Updates the kinematics Jacobians needed for getting the derivatives of the cost function\n",
    "        pinocchio.computeJointJacobians(model.pinocchio,data.pinocchio,q)\n",
    "        pinocchio.updateFramePlacements(model.pinocchio,data.pinocchio)\n",
    "        \n",
    "        # Computes all derivatives of cost function\n",
    "        model.costs.calcDiff(data.costs,x,u,recalc=False)\n",
    "        return data.xout,data.cost\n",
    "\n",
    "\n",
    "class DifferentialActionDataABA:\n",
    "    def __init__(self,model):\n",
    "        self.pinocchio = model.pinocchio.createData()\n",
    "        self.costs = model.costs.createData(self.pinocchio)\n",
    "        self.cost = np.nan\n",
    "        self.xout = np.zeros(model.nout)\n",
    "        nx,nu,ndx,nq,nv,nout = model.nx,model.nu,model.State.ndx,model.nq,model.nv,model.nout\n",
    "        self.F = np.zeros([ nout,ndx+nu ])\n",
    "        self.costResiduals = self.costs.residuals\n",
    "        self.Fx = self.F[:,:ndx]\n",
    "        self.Fu = self.F[:,-nu:]\n",
    "        self.g   = self.costs.g\n",
    "        self.L   = self.costs.L\n",
    "        self.Lx  = self.costs.Lx\n",
    "        self.Lu  = self.costs.Lu\n",
    "        self.Lxx = self.costs.Lxx\n",
    "        self.Lxu = self.costs.Lxu\n",
    "        self.Luu = self.costs.Luu\n",
    "        self.Rx  = self.costs.Rx\n",
    "        self.Ru  = self.costs.Ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.b State and its integrate and difference rules\n",
    "General speaking, the system's state can lie in a manifold $M$ where the state rate of change lies in its tangent space $T_\\mathbf{x}M$. There are few operators that needs to be defined for different rutines inside our solvers:\n",
    "  - $\\mathbf{x}_{k+1} = integrate(\\mathbf{x}_k,\\delta\\mathbf{x}_k) = \\mathbf{x}_k \\oplus \\delta\\mathbf{x}_k$\n",
    "  - $\\delta\\mathbf{x}_k = difference(\\mathbf{x}_{k+1},\\mathbf{x}_k) = \\mathbf{x}_{k+1} \\ominus \\mathbf{x}_k$\n",
    "\n",
    "where $\\mathbf{x}\\in M$ and $\\delta\\mathbf{x}\\in T_\\mathbf{x} M$.\n",
    " \n",
    "\n",
    "And we also need to defined the Jacobians of these operators with respect to the first and second arguments:\n",
    "  - $\\frac{\\partial \\mathbf{x}\\oplus\\delta\\mathbf{x}}{\\partial \\mathbf{x}}, \\frac{\\partial \\mathbf{x}\\oplus\\delta\\mathbf{x}}{\\partial\\delta\\mathbf{x}} =Jintegrante(\\mathbf{x},\\delta\\mathbf{x})$\n",
    "  - $\\frac{\\partial\\mathbf{x}_2\\ominus\\mathbf{x}_2}{\\partial \\mathbf{x}_1}, \\frac{\\partial \\mathbf{x}_2\\ominus\\mathbf{x}_1}{\\partial\\mathbf{x}_1} =Jdifference(\\mathbf{x}_2,\\mathbf{x}_1)$\n",
    "\n",
    "For instance, a state that lies in the Euclidean space will the typical operators:\n",
    "  - $integrate(\\mathbf{x},\\delta\\mathbf{x}) = \\mathbf{x} + \\delta\\mathbf{x}$\n",
    "  - $difference(\\mathbf{x}_2,\\mathbf{x}_1) = \\mathbf{x}_2 - \\mathbf{x}_1$\n",
    "  - $Jintegrate(\\cdot,\\cdot) = Jdifference(\\cdot,\\cdot) = \\mathbf{I}$\n",
    "  \n",
    "\n",
    "These defines inare encapsulate inside the State class. **For Pinocchio models, we have implemented the StatePinocchio class which can be used for any robot model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Solving optimal control problems with DDP\n",
    "\n",
    "## III.a ABA dynamics for reaching a goal with Talos arm\n",
    "\n",
    "Our optimal control solver interacts with a defined ShootingProblem. A shooting problem represents a stack of action models in which an action model defins a specific knot along the OC problem.\n",
    "\n",
    "First we need to create an action model from DifferentialActionModelABA. We use it for building terminal and running action models. In this example, we employ an simpletic Euler integration rule as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running and terminal action models\n",
    "runningModel = IntegratedActionModelEuler(DifferentialActionModelABA(talos_arm.model))\n",
    "terminalModel = IntegratedActionModelEuler(DifferentialActionModelABA(talos_arm.model))\n",
    "\n",
    "# Defining the time duration for running action models and the terminal one\n",
    "dt = 1e-3\n",
    "runningModel.timeStep = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the set of cost functions for this problem. For this particular example, we formulate three running-cost functions: \n",
    " - goal-tracking cost, $log(^fXd_o \\,^oX_f)$\n",
    "   \n",
    " - state and control regularization; and $\\|\\mathbf{x}-\\mathbf{x}_{ref}\\|, \\|\\mathbf{u}\\|$\n",
    "\n",
    "one terminal-cost:\n",
    " - goal cost. $\\|\\mathbf{u}_T\\|$\n",
    " \n",
    " First, let's create the common cost functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinocchio.utils import *\n",
    "\n",
    "# Goal tracking cost\n",
    "frameName = 'gripper_left_joint' #gripper_left_fingertip_2_link'\n",
    "state = StatePinocchio(talos_arm.model)\n",
    "SE3ref = pinocchio.SE3(np.eye(3), np.array([ [.0],[.0],[.4] ]))\n",
    "goalTrackingCost = CostModelFramePlacement(talos_arm.model,\n",
    "                                       nu=talos_arm.model.nv,\n",
    "                                       frame=talos_arm.model.getFrameId(frameName),\n",
    "                                       ref=SE3ref)\n",
    "\n",
    "# State and control regularization\n",
    "xRegCost = CostModelState(talos_arm.model,\n",
    "                          state,\n",
    "                          ref=state.zero(),\n",
    "                          nu=talos_arm.model.nv)\n",
    "uRegCost = CostModelControl(talos_arm.model,nu=talos_arm.model.nv)\n",
    "\n",
    "# Adds the running and terminal cost functions\n",
    "runningCostModel = runningModel.differential.costs\n",
    "runningCostModel.addCost( name=\"pos\", weight = 1e-3, cost = goalTrackingCost)\n",
    "runningCostModel.addCost( name=\"regx\", weight = 1e-7, cost = xRegCost) \n",
    "runningCostModel.addCost( name=\"regu\", weight = 1e-7, cost = uRegCost)\n",
    "terminalCostModel = terminalModel.differential.costs\n",
    "terminalCostModel.addCost( name=\"pos\", weight = 1, cost = goalTrackingCost)\n",
    "\n",
    "\n",
    "# Let's compute the cost and its derivatives\n",
    "robot_data = talos_arm.model.createData() # Pinocchio data\n",
    "data = goalTrackingCost.createData(robot_data)\n",
    "\n",
    "# Update kinematics\n",
    "q = pinocchio.randomConfiguration(talos_arm.model)\n",
    "v = rand(talos_arm.model.nv)\n",
    "x = m2a(np.concatenate([q,v]))\n",
    "u = m2a(rand(talos_arm.model.nv))\n",
    "pinocchio.forwardKinematics(talos_arm.model,robot_data,q,v)\n",
    "pinocchio.computeJointJacobians(talos_arm.model,robot_data,q)\n",
    "pinocchio.updateFramePlacements(talos_arm.model,robot_data)\n",
    "\n",
    "print 'cost =', goalTrackingCost.calc(data, x, u)\n",
    "print 'cost =', goalTrackingCost.calcDiff(data, x, u)\n",
    "print\n",
    "print 'lx =', data.Lx\n",
    "print 'lu =', data.Lu\n",
    "print\n",
    "print 'lxx =', data.Lxx\n",
    "print 'luu =', data.Luu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a trajectory with 250 knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this optimal control problem, we define 250 knots (or running action\n",
    "# models) plus a terminal knot\n",
    "T = 250\n",
    "problem = ShootingProblem(x0, [ runningModel ]*T, terminalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onces we have defined our shooting problem, we create a DDP solver object and pass some callback functions for analysing  its performance.\n",
    "\n",
    "Please note that:\n",
    "- CallbackDDPLogger: store the solution information.\n",
    "- CallbackDDPVerbose(level): printing message during the iterates.\n",
    "- CallbackSolverDisplay(robot,rate): display the state trajectory using Gepetto viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DDP solver for this OC problem, defining a logger\n",
    "ddp = SolverDDP(problem)\n",
    "cameraTF = [2., 2.68, 0.54, 0.2, 0.62, 0.72, 0.22]\n",
    "ddp.callback = [CallbackDDPLogger(), CallbackDDPVerbose(1), CallbackSolverDisplay(talos_arm,4,1,cameraTF)]\n",
    "\n",
    "# Solving it with the DDP algorithm\n",
    "ddp.solve()\n",
    "\n",
    "# Printing the reached position\n",
    "log = ddp.callback[0]\n",
    "frame_idx = talos_arm.model.getFrameId(frameName)\n",
    "xT = log.xs[-1]\n",
    "qT = np.asmatrix(xT[:talos_arm.model.nq]).T\n",
    "print\n",
    "print \"The reached pose by the wrist is\"\n",
    "print talos_arm.framePlacement(qT, frame_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results and display final trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Plotting the solution and the DDP convergence\n",
    "log = ddp.callback[0]\n",
    "plotOCSolution(log.xs, log.us)\n",
    "plotDDPConvergence(log.costs,log.control_regs,\n",
    "                   log.state_regs,log.gm_stops,\n",
    "                   log.th_stops,log.steps)\n",
    "\n",
    "# Visualizing the solution in gepetto-viewer\n",
    "CallbackSolverDisplay(talos_arm)(ddp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.b Multi-Contact dynamics for biped walking (Talos legs)\n",
    "In crocoddyl, we can describe the multi-contact dynamics through holonomic constraints for the support legs. From the Gauss principle, we have derived the model as:\n",
    "$$\n",
    "\\left[\\begin{matrix}\n",
    " \\mathbf{M} & \\mathbf{J}^{\\top}_c \\\\\n",
    " {\\mathbf{J}_{c}} & \\mathbf{0} \\\\\n",
    "\\end{matrix}\\right]\n",
    "\\left[\\begin{matrix}\n",
    " \\dot{\\mathbf{v}} \\\\ -\\boldsymbol{\\lambda}\n",
    "\\end{matrix}\\right]\n",
    " = \n",
    "\\left[\\begin{matrix}\n",
    "  \\boldsymbol{\\tau} - \\mathbf{h} \\\\\n",
    "  -\\dot{\\mathbf{J}}_c \\mathbf{v} \\\\\n",
    "\\end{matrix}\\right]$$.\n",
    "\n",
    "This DAM is defined in \"DifferentialActionModelFloatingInContact\" class.\n",
    "\n",
    "Given a predefined contact sequence and timings, we build per each phase a specific multi-contact dynamics. Indeed we need to describe multi-phase optimal control problem. One can formulate the multi-contact optimal control problem (MCOP) as follows:\n",
    "\n",
    "\n",
    "$$\\mathbf{X}^*,\\mathbf{U}^*=\n",
    "\\begin{Bmatrix} \\mathbf{x}^*_0,\\cdots,\\mathbf{x}^*_N \\\\\n",
    "\t\t\t\t  \\mathbf{u}^*_0,\\cdots,\\mathbf{u}^*_N\n",
    "\\end{Bmatrix} =\n",
    "\\arg\\min_{\\mathbf{X},\\mathbf{U}} \\sum_{p=0}^P \\sum_{k=1}^{N(p)} \\int_{t_k}^{t_k+\\Delta t} l_p(\\mathbf{x},\\mathbf{u})dt$$\n",
    "subject to\n",
    "$$ \\mathbf{\\dot{x}} = \\mathbf{f}_p(\\mathbf{x},\\mathbf{u}), \\text{for } t \\in [\\tau_p,\\tau_{p+1}]$$\n",
    "\n",
    "$$ \\mathbf{g}(\\mathbf{v}^{p+1},\\mathbf{v}^p) = \\mathbf{0}$$\n",
    "\n",
    "$$ \\mathbf{x}\\in\\mathcal{X}_p, \\mathbf{u}\\in\\mathcal{U}_p, \\boldsymbol{\\lambda}\\in\\mathcal{K}_p.$$\n",
    "\n",
    "where $\\mathbf{g}(\\cdot,\\cdot,\\cdot)$ describes the contact dynamics, and they represents terminal constraints in each walking phase. In this example we use the following impact model:\n",
    "\n",
    "$$\\mathbf{M}(\\mathbf{v}_{next}-\\mathbf{v}) = \\mathbf{J}_{impulse}^T$$\n",
    "\n",
    "$$\\mathbf{J}_{impulse} \\mathbf{v}_{next} = \\mathbf{0}$$\n",
    "\n",
    "$$\\mathbf{J}_{c} \\mathbf{v}_{next} = \\mathbf{J}_{c} \\mathbf{v}$$\n",
    "\n",
    "### Note:\n",
    "You can find an example of such kind of problems in bipedal_walking_from_foot_traj.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "The material presented in this Notebook was previously presented at the ICHR at 2018. For more information, please read the following paper:\n",
    "\n",
    "R. Budhiraja, J. Carpentier, C. Mastalli and N. Mansard. *Differential Dynamic Programming for Multi-Phase Rigid Contact Dynamics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/X82tFTR4Mcc?start=11\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![title](https://cmastalli.github.io/assets/img/publications/astronaut360_v2.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
